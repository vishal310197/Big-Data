{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a6c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import findspark\n",
    "findspark.init('C:\\spark\\spark-3.1.2-bin-hadoop3.2')\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import *\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8694547c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---------+\n",
      "| ID| Name|Grad_Prog|\n",
      "+---+-----+---------+\n",
      "|  1|  Tom|        1|\n",
      "|  2| Bill|        2|\n",
      "|  3| Bond|        3|\n",
      "|  4|James|        4|\n",
      "|  5|Steve|        5|\n",
      "+---+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+-------+--------+\n",
      "|Grad_Prog| Degree|  School|\n",
      "+---------+-------+--------+\n",
      "|        1|Masters|     MIT|\n",
      "|        2|Masters|     MIT|\n",
      "|        3|Masters|Stanford|\n",
      "|        4|    Phd| Harvard|\n",
      "|        5|    Phd|Stanford|\n",
      "+---------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "student = spark.read.option(\"inferschema\",\"true\").option(\"header\",\"true\").csv(\"students.csv\")\n",
    "program = spark.read.option(\"inferschema\",\"true\").option(\"header\",\"true\").csv(\"program.csv\")\n",
    "student.show(5)\n",
    "program.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc8ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "student.createOrReplaceTempView(\"STUDENT\")\n",
    "program.createOrReplaceTempView(\"PROGRAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ecebc7",
   "metadata": {},
   "source": [
    "# Join Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e92e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join types include: \n",
    "#'inner', 'outer', 'full', 'fullouter', 'full_outer', \n",
    "#'leftouter', 'left', 'left_outer', 'rightouter', \n",
    "#'right', 'right_outer', \n",
    "#'leftsemi', 'left_semi', 'semi', \n",
    "#'leftanti', 'left_anti', 'anti', \n",
    "#'cross'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e83a6e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+-----+-------+--------+\n",
      "|Grad_Prog| ID| Name| Degree|  School|\n",
      "+---------+---+-----+-------+--------+\n",
      "|        1|  1|  Tom|Masters|     MIT|\n",
      "|        2|  2| Bill|Masters|     MIT|\n",
      "|        3|  3| Bond|Masters|Stanford|\n",
      "|        4|  4|James|    Phd| Harvard|\n",
      "|        5|  5|Steve|    Phd|Stanford|\n",
      "|        6|  6|Chris|    Phd|Stanford|\n",
      "|        7|  7|Peter|Diploma|Stanford|\n",
      "|        8|  8| Paul|Diploma|     MIT|\n",
      "|        9|  9|  Rob|    Phd|     MIT|\n",
      "|       10| 10|  Max|Masters| Harvard|\n",
      "+---------+---+-----+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Natural Join\n",
    "#Matches Column with same name\n",
    "#No condition is provided, only works when there is a column in both tables with same name\n",
    "#Here we will match grad_prog from both tables\n",
    "\n",
    "spark.sql('SELECT * FROM STUDENT NATURAL JOIN PROGRAM').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e046991b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---------+---------+-------+--------+\n",
      "| ID| Name|Grad_Prog|Grad_Prog| Degree|  School|\n",
      "+---+-----+---------+---------+-------+--------+\n",
      "|  1|  Tom|        1|        1|Masters|     MIT|\n",
      "|  2| Bill|        2|        2|Masters|     MIT|\n",
      "|  3| Bond|        3|        3|Masters|Stanford|\n",
      "|  4|James|        4|        4|    Phd| Harvard|\n",
      "|  5|Steve|        5|        5|    Phd|Stanford|\n",
      "|  6|Chris|        6|        6|    Phd|Stanford|\n",
      "|  7|Peter|        7|        7|Diploma|Stanford|\n",
      "|  8| Paul|        8|        8|Diploma|     MIT|\n",
      "|  9|  Rob|        9|        9|    Phd|     MIT|\n",
      "| 10|  Max|       10|       10|Masters| Harvard|\n",
      "+---+-----+---------+---------+-------+--------+\n",
      "\n",
      "+---+-----+---------+---------+-------+--------+\n",
      "| ID| Name|Grad_Prog|Grad_Prog| Degree|  School|\n",
      "+---+-----+---------+---------+-------+--------+\n",
      "|  1|  Tom|        1|        1|Masters|     MIT|\n",
      "|  2| Bill|        2|        2|Masters|     MIT|\n",
      "|  3| Bond|        3|        3|Masters|Stanford|\n",
      "|  4|James|        4|        4|    Phd| Harvard|\n",
      "|  5|Steve|        5|        5|    Phd|Stanford|\n",
      "|  6|Chris|        6|        6|    Phd|Stanford|\n",
      "|  7|Peter|        7|        7|Diploma|Stanford|\n",
      "|  8| Paul|        8|        8|Diploma|     MIT|\n",
      "|  9|  Rob|        9|        9|    Phd|     MIT|\n",
      "| 10|  Max|       10|       10|Masters| Harvard|\n",
      "+---+-----+---------+---------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Inner Join\n",
    "#Join with a condition\n",
    "\n",
    "student.join(program, student.ID == program.Grad_Prog,'inner').show()\n",
    "#student.join(program, student.ID == program.Grad_Prog).show()\n",
    "#program.join(student, program.Grad_Prog == student.ID,'inner').show()\n",
    "\n",
    "spark.sql('SELECT * FROM STUDENT INNER JOIN PROGRAM ON STUDENT.ID == PROGRAM.Grad_Prog').show()\n",
    "#spark.sql('SELECT * FROM STUDENT JOIN PROGRAM ON STUDENT.ID == PROGRAM.Grad_Prog').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0661044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---------+---------+---------+--------+\n",
      "|  ID| Name|Grad_Prog|Grad_Prog|   Degree|  School|\n",
      "+----+-----+---------+---------+---------+--------+\n",
      "|   1|  Tom|        1|        1|  Masters|     MIT|\n",
      "|   2| Bill|        2|        2|  Masters|     MIT|\n",
      "|   3| Bond|        3|        3|  Masters|Stanford|\n",
      "|   4|James|        4|        4|      Phd| Harvard|\n",
      "|   5|Steve|        5|        5|      Phd|Stanford|\n",
      "|   6|Chris|        6|        6|      Phd|Stanford|\n",
      "|   7|Peter|        7|        7|  Diploma|Stanford|\n",
      "|   8| Paul|        8|        8|  Diploma|     MIT|\n",
      "|   9|  Rob|        9|        9|      Phd|     MIT|\n",
      "|  10|  Max|       10|       10|  Masters| Harvard|\n",
      "|null| null|     null|       11|Bachelors| Harvard|\n",
      "|null| null|     null|       12|      Phd|     MIT|\n",
      "|null| null|     null|       13|  Diploma|     MIT|\n",
      "+----+-----+---------+---------+---------+--------+\n",
      "\n",
      "+---------+---------+--------+----+-----+---------+\n",
      "|Grad_Prog|   Degree|  School|  ID| Name|Grad_Prog|\n",
      "+---------+---------+--------+----+-----+---------+\n",
      "|        1|  Masters|     MIT|   1|  Tom|        1|\n",
      "|        2|  Masters|     MIT|   2| Bill|        2|\n",
      "|        3|  Masters|Stanford|   3| Bond|        3|\n",
      "|        4|      Phd| Harvard|   4|James|        4|\n",
      "|        5|      Phd|Stanford|   5|Steve|        5|\n",
      "|        6|      Phd|Stanford|   6|Chris|        6|\n",
      "|        7|  Diploma|Stanford|   7|Peter|        7|\n",
      "|        8|  Diploma|     MIT|   8| Paul|        8|\n",
      "|        9|      Phd|     MIT|   9|  Rob|        9|\n",
      "|       10|  Masters| Harvard|  10|  Max|       10|\n",
      "|       11|Bachelors| Harvard|null| null|     null|\n",
      "|       12|      Phd|     MIT|null| null|     null|\n",
      "|       13|  Diploma|     MIT|null| null|     null|\n",
      "+---------+---------+--------+----+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Right Outer Join\n",
    "#Outputs whole right table ,fills null if left one does not have values\n",
    "student.join(program, student.ID == program.Grad_Prog,'right_outer').show()\n",
    "#student.join(program, student.ID == program.Grad_Prog,'right').show()\n",
    "\n",
    "#spark.sql('SELECT * FROM STUDENT RIGHT OUTER JOIN PROGRAM ON STUDENT.ID == PROGRAM.Grad_Prog').show()\n",
    "\n",
    "#Left Outer Join\n",
    "#Outputs whole left\n",
    "program.join(student, program.Grad_Prog == student.ID,'left_outer').show()\n",
    "#program.join(student, program.Grad_Prog == student.ID,'left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4d9566c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---------+\n",
      "| ID| Name|Grad_Prog|\n",
      "+---+-----+---------+\n",
      "|  1|  Tom|        1|\n",
      "|  2| Bill|        2|\n",
      "|  3| Bond|        3|\n",
      "|  4|James|        4|\n",
      "|  5|Steve|        5|\n",
      "|  6|Chris|        6|\n",
      "|  7|Peter|        7|\n",
      "|  8| Paul|        8|\n",
      "|  9|  Rob|        9|\n",
      "| 10|  Max|       10|\n",
      "+---+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Semi Joins\n",
    "#They are like filters\n",
    "student.join(program, student.ID == program.Grad_Prog,'left_semi').show()\n",
    "#student.join(program, student.ID == program.Grad_Prog,'semi').show()\n",
    "\n",
    "#spark.sql('SELECT * FROM STUDENT LEFT SEMI JOIN PROGRAM ON STUDENT.ID == PROGRAM.Grad_Prog').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62062020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---------+\n",
      "| ID|Name|Grad_Prog|\n",
      "+---+----+---------+\n",
      "+---+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Anti joins\n",
    "#Opposite of semi\n",
    "student.join(program, student.ID == program.Grad_Prog,'left_anti').show()\n",
    "\n",
    "#spark.sql('SELECT * FROM STUDENT LEFT ANTI JOIN PROGRAM ON STUDENT.ID == PROGRAM.Grad_Prog').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e026fdb",
   "metadata": {},
   "source": [
    "# Physical Plan of Each Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a660b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Project [Grad_Prog#18, ID#16, Name#17, Degree#39, School#40]\n",
      "+- *(2) BroadcastHashJoin [Grad_Prog#18], [Grad_Prog#38], Inner, BuildLeft, false\n",
      "   :- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[2, int, false] as bigint)),false), [id=#2338]\n",
      "   :  +- *(1) Filter isnotnull(Grad_Prog#18)\n",
      "   :     +- FileScan csv [ID#16,Name#17,Grad_Prog#18] Batched: false, DataFilters: [isnotnull(Grad_Prog#18)], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/students.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Grad_Prog)], ReadSchema: struct<ID:int,Name:string,Grad_Prog:int>\n",
      "   +- *(2) Filter isnotnull(Grad_Prog#38)\n",
      "      +- FileScan csv [Grad_Prog#38,Degree#39,School#40] Batched: false, DataFilters: [isnotnull(Grad_Prog#38)], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/program.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Grad_Prog)], ReadSchema: struct<Grad_Prog:int,Degree:string,School:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Natural Join\n",
    "spark.sql('SELECT * FROM STUDENT NATURAL JOIN PROGRAM').explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d298344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [ID#16], [Grad_Prog#38], Inner, BuildLeft, false\n",
      ":- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#2370]\n",
      ":  +- *(1) Filter isnotnull(ID#16)\n",
      ":     +- FileScan csv [ID#16,Name#17,Grad_Prog#18] Batched: false, DataFilters: [isnotnull(ID#16)], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/students.csv], PartitionFilters: [], PushedFilters: [IsNotNull(ID)], ReadSchema: struct<ID:int,Name:string,Grad_Prog:int>\n",
      "+- *(2) Filter isnotnull(Grad_Prog#38)\n",
      "   +- FileScan csv [Grad_Prog#38,Degree#39,School#40] Batched: false, DataFilters: [isnotnull(Grad_Prog#38)], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/program.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Grad_Prog)], ReadSchema: struct<Grad_Prog:int,Degree:string,School:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Inner Join\n",
    "student.join(program, student.ID == program.Grad_Prog,'inner').explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d70d2637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [ID#16], [Grad_Prog#38], RightOuter, BuildLeft, false\n",
      ":- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#2454]\n",
      ":  +- *(1) Filter isnotnull(ID#16)\n",
      ":     +- FileScan csv [ID#16,Name#17,Grad_Prog#18] Batched: false, DataFilters: [isnotnull(ID#16)], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/students.csv], PartitionFilters: [], PushedFilters: [IsNotNull(ID)], ReadSchema: struct<ID:int,Name:string,Grad_Prog:int>\n",
      "+- FileScan csv [Grad_Prog#38,Degree#39,School#40] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/program.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Grad_Prog:int,Degree:string,School:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Right Outer Join\n",
    "student.join(program, student.ID == program.Grad_Prog,'right_outer').explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73eee5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [ID#16], [Grad_Prog#38], LeftSemi, BuildRight, false\n",
      ":- *(2) Filter isnotnull(ID#16)\n",
      ":  +- FileScan csv [ID#16,Name#17,Grad_Prog#18] Batched: false, DataFilters: [isnotnull(ID#16)], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/students.csv], PartitionFilters: [], PushedFilters: [IsNotNull(ID)], ReadSchema: struct<ID:int,Name:string,Grad_Prog:int>\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#2486]\n",
      "   +- *(1) Filter isnotnull(Grad_Prog#38)\n",
      "      +- FileScan csv [Grad_Prog#38] Batched: false, DataFilters: [isnotnull(Grad_Prog#38)], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/program.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Grad_Prog)], ReadSchema: struct<Grad_Prog:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#semi joins\n",
    "student.join(program, student.ID == program.Grad_Prog,'left_semi').explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "160eb51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [ID#16], [Grad_Prog#38], LeftAnti, BuildRight, false\n",
      ":- FileScan csv [ID#16,Name#17,Grad_Prog#18] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/students.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ID:int,Name:string,Grad_Prog:int>\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#2512]\n",
      "   +- *(1) Filter isnotnull(Grad_Prog#38)\n",
      "      +- FileScan csv [Grad_Prog#38] Batched: false, DataFilters: [isnotnull(Grad_Prog#38)], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/program.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Grad_Prog)], ReadSchema: struct<Grad_Prog:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#anti\n",
    "student.join(program, student.ID == program.Grad_Prog,'left_anti').explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0368e3",
   "metadata": {},
   "source": [
    "# Physical Plan Of Basic Spark/SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2bf52252",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = spark.read.option(\"inferschema\",\"true\").option(\"header\",\"true\").csv(\"bus.csv\")\n",
    "bus.createTempView('BUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c19ef1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[Degree#39], functions=[count(1)])\n",
      "+- Exchange hashpartitioning(Degree#39, 200), ENSURE_REQUIREMENTS, [id=#2550]\n",
      "   +- *(1) HashAggregate(keys=[Degree#39], functions=[partial_count(1)])\n",
      "      +- FileScan csv [Degree#39] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/program.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Degree:string>\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[Degree#39], functions=[sum(cast(Grad_Prog#38 as bigint))])\n",
      "+- Exchange hashpartitioning(Degree#39, 200), ENSURE_REQUIREMENTS, [id=#2569]\n",
      "   +- *(1) HashAggregate(keys=[Degree#39], functions=[partial_sum(cast(Grad_Prog#38 as bigint))])\n",
      "      +- FileScan csv [Grad_Prog#38,Degree#39] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/program.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Grad_Prog:int,Degree:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "program.groupBy('Degree').count().explain()\n",
    "program.groupBy('Degree').sum().explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c360765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[Town#2418], functions=[count(1)])\n",
      "+- Exchange hashpartitioning(Town#2418, 200), ENSURE_REQUIREMENTS, [id=#2648]\n",
      "   +- *(1) HashAggregate(keys=[Town#2418], functions=[partial_count(1)])\n",
      "      +- FileScan csv [Town#2418] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/bus.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Town:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#How many breakdowns occurred in total in each town\n",
    "bus.select(col(\"Town\"),col(\"Busbreakdown_ID\")).groupBy(col(\"Town\")).count().explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b94a60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Sort [School_Year#2411 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(School_Year#2411 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#2697]\n",
      "   +- *(2) HashAggregate(keys=[School_Year#2411, Town#2418], functions=[count(1)])\n",
      "      +- Exchange hashpartitioning(School_Year#2411, Town#2418, 200), ENSURE_REQUIREMENTS, [id=#2693]\n",
      "         +- *(1) HashAggregate(keys=[School_Year#2411, Town#2418], functions=[partial_count(1)])\n",
      "            +- FileScan csv [School_Year#2411,Town#2418] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/bus.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<School_Year:int,Town:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#How many breakdowns occurred in total in each town per year\n",
    "bus.select(col(\"School_Year\"),col(\"Town\"),col(\"Busbreakdown_ID\")).groupBy(\"School_Year\",\"Town\").count().orderBy(\"School_Year\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "388c0fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Sort [School_Year#2411 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(School_Year#2411 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#2813]\n",
      "   +- *(2) HashAggregate(keys=[School_Year#2411], functions=[sum(cast(Busbreakdown_ID#2412 as bigint))])\n",
      "      +- Exchange hashpartitioning(School_Year#2411, 200), ENSURE_REQUIREMENTS, [id=#2809]\n",
      "         +- *(1) HashAggregate(keys=[School_Year#2411], functions=[partial_sum(cast(Busbreakdown_ID#2412 as bigint))])\n",
      "            +- *(1) Project [School_Year#2411, Busbreakdown_ID#2412]\n",
      "               +- *(1) Filter (isnotnull(Town#2418) AND (Town#2418 = Brooklyn))\n",
      "                  +- FileScan csv [School_Year#2411,Busbreakdown_ID#2412,Town#2418] Batched: false, DataFilters: [isnotnull(Town#2418), (Town#2418 = Brooklyn)], Format: CSV, Location: InMemoryFileIndex[file:/C:/Users/HI/big data/bus.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Town), EqualTo(Town,Brooklyn)], ReadSchema: struct<School_Year:int,Busbreakdown_ID:int,Town:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#how many breakdowns occur each year in brooklyn\n",
    "bus.filter(col(\"Town\")==\"Brooklyn\").groupBy(\"School_Year\").agg(sum(\"Busbreakdown_ID\").alias(\"Total\")).orderBy(\"School_Year\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd14c020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
